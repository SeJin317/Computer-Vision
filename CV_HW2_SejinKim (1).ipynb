{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fvPY6-zwP2Zx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class LFW4Training(Dataset):\n",
        "    def __init__(self, train_file: str, img_folder: str):\n",
        "        self.img_folder = img_folder\n",
        "\n",
        "        names = os.listdir(img_folder)\n",
        "        self.name2label = {name: idx for idx, name in enumerate(names)}\n",
        "        self.n_label = len(self.name2label)\n",
        "\n",
        "        with open(train_file) as f:\n",
        "            train_meta_info = f.read().splitlines()\n",
        "\n",
        "        self.train_list = []\n",
        "        for line in train_meta_info:\n",
        "            line = line.split(\"\\t\")\n",
        "            if len(line) == 3:\n",
        "                self.train_list.append(os.path.join(line[0], line[0] + \"_\" + str(line[1]).zfill(4) + \".jpg\"))\n",
        "                self.train_list.append(os.path.join(line[0], line[0] + \"_\" + str(line[2]).zfill(4) + \".jpg\"))\n",
        "            elif len(line) == 4:\n",
        "                self.train_list.append(os.path.join(line[0], line[0] + \"_\" + str(line[1]).zfill(4) + \".jpg\"))\n",
        "                self.train_list.append(os.path.join(line[2], line[2] + \"_\" + str(line[3]).zfill(4) + \".jpg\"))\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(96),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                 std=[0.5, 0.5, 0.5]),\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.train_list[index]\n",
        "\n",
        "        img = Image.open(os.path.join(self.img_folder, img_path))\n",
        "        img = self.transform(img)\n",
        "\n",
        "        name = img_path.split(\"/\")[0]\n",
        "        label = self.name2label[name]\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_list)\n",
        "\n",
        "\n",
        "class LFW4Eval(Dataset):\n",
        "    def __init__(self, eval_file: str, img_folder: str):\n",
        "        self.img_folder = img_folder\n",
        "\n",
        "        with open(eval_file) as f:\n",
        "            eval_meta_info = f.read().splitlines()\n",
        "\n",
        "        self.eval_list = []\n",
        "        for line in eval_meta_info:\n",
        "            line = line.split(\"\\t\")\n",
        "            if len(line) == 3:\n",
        "                eval_pair = (\n",
        "                    os.path.join(line[0], line[0] + \"_\" + str(line[1]).zfill(4) + \".jpg\"),\n",
        "                    os.path.join(line[0], line[0] + \"_\" + str(line[2]).zfill(4) + \".jpg\"),\n",
        "                    1,\n",
        "                )\n",
        "                self.eval_list.append(eval_pair)\n",
        "            elif len(line) == 4:\n",
        "                eval_pair = (\n",
        "                    os.path.join(line[0], line[0] + \"_\" + str(line[1]).zfill(4) + \".jpg\"),\n",
        "                    os.path.join(line[2], line[2] + \"_\" + str(line[3]).zfill(4) + \".jpg\"),\n",
        "                    0,\n",
        "                )\n",
        "                self.eval_list.append(eval_pair)\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(96),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                 std=[0.5, 0.5, 0.5]),\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_1_path, img_2_path, label = self.eval_list[index]\n",
        "\n",
        "        img_1 = Image.open(os.path.join(self.img_folder, img_1_path))\n",
        "        img_2 = Image.open(os.path.join(self.img_folder, img_2_path))\n",
        "        img_1 = self.transform(img_1)\n",
        "        img_2 = self.transform(img_2)\n",
        "\n",
        "        return img_1, img_2, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.eval_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class AngularPenaltySMLoss(nn.Module):\n",
        "    def __init__(self, in_features, out_features, eps=1e-7, m=None):\n",
        "        super(AngularPenaltySMLoss, self).__init__()\n",
        "\n",
        "        self.m = 4. if not m else m\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "\n",
        "        '''\n",
        "        input shape (N, in_features)\n",
        "        '''\n",
        "        assert len(x) == len(labels)\n",
        "        assert torch.min(labels) >= 0\n",
        "        assert torch.max(labels) < self.out_features\n",
        "\n",
        "        for W in self.fc.parameters():\n",
        "            W = F.normalize(W, p=2, dim=1)\n",
        "\n",
        "        x = F.normalize(x, p=2, dim=1)\n",
        "\n",
        "        wf = self.fc(x)\n",
        "\n",
        "        numerator = torch.cos(self.m * torch.acos(\n",
        "            torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1. + self.eps, 1 - self.eps)))\n",
        "\n",
        "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y + 1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
        "        denominator = torch.exp(numerator) + torch.sum(torch.exp(excl), dim=1)\n",
        "        L = numerator - torch.log(denominator)\n",
        "\n",
        "        return -torch.mean(L)\n",
        "\n",
        "\n",
        "class SphereCNN(nn.Module):\n",
        "    def __init__(self, class_num: int, feature=False):\n",
        "        super(SphereCNN, self).__init__()\n",
        "        self.class_num = class_num\n",
        "        self.feature = feature\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=128, kernel_size=3, stride=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2)\n",
        "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2)\n",
        "\n",
        "        self.fc5 = nn.Linear(512 * 5 * 5, 512)\n",
        "        self.angular = AngularPenaltySMLoss(512, self.class_num)\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc5(x)\n",
        "\n",
        "        if self.feature or y is None:\n",
        "            return x\n",
        "        else:\n",
        "            x_angle = self.angular(x, y)\n",
        "            return x, x_angle\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    net = SphereCNN(50)\n",
        "    input = torch.ones(64, 3, 96, 96)\n",
        "    output = net(input, None)"
      ],
      "metadata": {
        "id": "oTJaTy7TQOta"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\"SphereFace\")\n",
        "\n",
        "    parser.add_argument('--seed', type=int, default=2021)\n",
        "    parser.add_argument('--device', type=str, default=\"cuda:0\")\n",
        "\n",
        "    parser.add_argument('--batch_size', type=int, default=128)\n",
        "    parser.add_argument('--epoch', type=int, default=100)\n",
        "    parser.add_argument('--lr', type=float, default=1e-3)\n",
        "    parser.add_argument('--eval_interval', type=int, default=20)\n",
        "\n",
        "    parser.add_argument('--train_file', type=str, default='/content/pairsDevTrain.txt')\n",
        "    parser.add_argument('--eval_file', type=str, default='/content/pairsDevTest.txt')\n",
        "    parser.add_argument('--img_folder', type=str, default='/content/lfw')\n",
        "\n",
        "    return parser.parse_args()"
      ],
      "metadata": {
        "id": "0-rVfZF5SYgX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.argv = [\n",
        "    'main.py',  # This is just a placeholder for the script name and isn't used in the argument parsing.\n",
        "    '--seed', '2021',  # Seed for random number generators for reproducibility.\n",
        "    '--device', 'cuda:0',  # Specify the device for computation (use 'cpu' if GPU is not available).\n",
        "    '--batch_size', '128',  # Batch size for training and evaluation.\n",
        "    '--epoch', '100',  # Number of epochs to train for.\n",
        "    '--lr', '0.001',  # Learning rate for optimizer.\n",
        "    '--eval_interval', '20',  # Interval (in epochs) at which to perform evaluation on the validation set.\n",
        "    '--train_file', '/content/pairsDevTest.txt',  # Path to the training pairs file.\n",
        "    '--eval_file', '/content/pairsDevTest.txt',  # Path to the evaluation/testing pairs file.\n",
        "    '--img_folder', '/content/lfw'  # Path to the directory containing the LFW images.\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "1v4c9DV_dyY4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "f-yy_X3qSbWA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def eval(data_loader: DataLoader, model: SphereCNN, device: torch.device, threshold: float = 0.5):\n",
        "    model.eval()\n",
        "    model.feature = True\n",
        "    sim_func = nn.CosineSimilarity()\n",
        "\n",
        "    cnt = 0.\n",
        "    total = 0.\n",
        "\n",
        "    t1 = time.time()\n",
        "    with torch.no_grad():\n",
        "        for img_1, img_2, label in data_loader:\n",
        "            img_1 = img_1.to(device)\n",
        "            img_2 = img_2.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            feat_1 = model(img_1, None)\n",
        "            feat_2 = model(img_2, None)\n",
        "            sim = sim_func(feat_1, feat_2)\n",
        "\n",
        "            sim[sim > threshold] = 1\n",
        "            sim[sim <= threshold] = 0\n",
        "\n",
        "            total += sim.size(0)\n",
        "            for i in range(sim.size(0)):\n",
        "                if sim[i] == label[i]:\n",
        "                    cnt += 1\n",
        "\n",
        "    print(\"Acc.: %.4f; Time: %.3f\" % (cnt / total, time.time() - t1))\n",
        "    return\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "\n",
        "    set_seed(args.seed)\n",
        "    device = torch.device(args.device)\n",
        "\n",
        "    train_set = LFW4Training(args.train_file, args.img_folder)\n",
        "    eval_set = LFW4Eval(args.eval_file, args.img_folder)\n",
        "    train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True)\n",
        "    eval_loader = DataLoader(eval_set, batch_size=args.batch_size)\n",
        "\n",
        "    model = SphereCNN(class_num=train_set.n_label)\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "    loss_record = AverageMeter()\n",
        "    for epoch in range(args.epoch):\n",
        "        t1 = time.time()\n",
        "        model.train()\n",
        "        model.feature = False\n",
        "        loss_record.reset()\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            _, loss = model(inputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_record.update(loss)\n",
        "\n",
        "        print(\"Epoch: %s; Loss: %.3f; Time: %.3f\" % (str(epoch).zfill(2), loss_record.avg, time.time() - t1))\n",
        "\n",
        "        if (epoch + 1) % args.eval_interval == 0:\n",
        "            eval(eval_loader, model, device)\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twNGMfy5QFEs",
        "outputId": "e51c3f8c-a1cf-4108-b3f0-6eb597f2ab49"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 00; Loss: 7.617; Time: 7.276\n",
            "Epoch: 01; Loss: 7.378; Time: 4.206\n",
            "Epoch: 02; Loss: 7.115; Time: 3.838\n",
            "Epoch: 03; Loss: 6.884; Time: 4.180\n",
            "Epoch: 04; Loss: 6.688; Time: 4.581\n",
            "Epoch: 05; Loss: 6.528; Time: 3.859\n",
            "Epoch: 06; Loss: 6.401; Time: 3.831\n",
            "Epoch: 07; Loss: 6.302; Time: 5.875\n",
            "Epoch: 08; Loss: 6.223; Time: 4.040\n",
            "Epoch: 09; Loss: 6.162; Time: 4.445\n",
            "Epoch: 10; Loss: 6.116; Time: 4.856\n",
            "Epoch: 11; Loss: 6.076; Time: 3.898\n",
            "Epoch: 12; Loss: 6.044; Time: 3.861\n",
            "Epoch: 13; Loss: 6.018; Time: 4.916\n",
            "Epoch: 14; Loss: 5.995; Time: 3.868\n",
            "Epoch: 15; Loss: 5.975; Time: 3.848\n",
            "Epoch: 16; Loss: 5.956; Time: 4.912\n",
            "Epoch: 17; Loss: 5.938; Time: 3.839\n",
            "Epoch: 18; Loss: 5.918; Time: 3.924\n",
            "Epoch: 19; Loss: 5.899; Time: 4.805\n",
            "Acc.: 0.5000; Time: 3.432\n",
            "Epoch: 20; Loss: 5.879; Time: 3.834\n",
            "Epoch: 21; Loss: 5.857; Time: 4.194\n",
            "Epoch: 22; Loss: 5.833; Time: 5.079\n",
            "Epoch: 23; Loss: 5.807; Time: 3.880\n",
            "Epoch: 24; Loss: 5.782; Time: 4.167\n",
            "Epoch: 25; Loss: 5.755; Time: 4.667\n",
            "Epoch: 26; Loss: 5.727; Time: 3.889\n",
            "Epoch: 27; Loss: 5.700; Time: 3.950\n",
            "Epoch: 28; Loss: 5.674; Time: 4.906\n",
            "Epoch: 29; Loss: 5.645; Time: 3.928\n",
            "Epoch: 30; Loss: 5.618; Time: 3.853\n",
            "Epoch: 31; Loss: 5.587; Time: 4.916\n",
            "Epoch: 32; Loss: 5.559; Time: 3.904\n",
            "Epoch: 33; Loss: 5.532; Time: 3.820\n",
            "Epoch: 34; Loss: 5.502; Time: 5.621\n",
            "Epoch: 35; Loss: 5.471; Time: 4.493\n",
            "Epoch: 36; Loss: 5.442; Time: 4.437\n",
            "Epoch: 37; Loss: 5.412; Time: 4.789\n",
            "Epoch: 38; Loss: 5.389; Time: 4.029\n",
            "Epoch: 39; Loss: 5.361; Time: 3.828\n",
            "Acc.: 0.5770; Time: 3.557\n",
            "Epoch: 40; Loss: 5.332; Time: 4.681\n",
            "Epoch: 41; Loss: 5.302; Time: 3.900\n",
            "Epoch: 42; Loss: 5.267; Time: 3.917\n",
            "Epoch: 43; Loss: 5.244; Time: 4.860\n",
            "Epoch: 44; Loss: 5.212; Time: 3.878\n",
            "Epoch: 45; Loss: 5.182; Time: 3.909\n",
            "Epoch: 46; Loss: 5.145; Time: 4.869\n",
            "Epoch: 47; Loss: 5.116; Time: 3.847\n",
            "Epoch: 48; Loss: 5.087; Time: 3.834\n",
            "Epoch: 49; Loss: 5.059; Time: 5.169\n",
            "Epoch: 50; Loss: 5.025; Time: 4.300\n",
            "Epoch: 51; Loss: 4.993; Time: 4.062\n",
            "Epoch: 52; Loss: 4.955; Time: 5.313\n",
            "Epoch: 53; Loss: 4.935; Time: 4.179\n",
            "Epoch: 54; Loss: 4.906; Time: 4.137\n",
            "Epoch: 55; Loss: 4.886; Time: 5.249\n",
            "Epoch: 56; Loss: 4.856; Time: 4.127\n",
            "Epoch: 57; Loss: 4.820; Time: 4.029\n",
            "Epoch: 58; Loss: 4.787; Time: 4.948\n",
            "Epoch: 59; Loss: 4.758; Time: 4.011\n",
            "Acc.: 0.6610; Time: 3.790\n",
            "Epoch: 60; Loss: 4.731; Time: 5.173\n",
            "Epoch: 61; Loss: 4.697; Time: 4.079\n",
            "Epoch: 62; Loss: 4.666; Time: 4.386\n",
            "Epoch: 63; Loss: 4.639; Time: 4.620\n",
            "Epoch: 64; Loss: 4.605; Time: 4.178\n",
            "Epoch: 65; Loss: 4.583; Time: 3.870\n",
            "Epoch: 66; Loss: 4.548; Time: 4.364\n",
            "Epoch: 67; Loss: 4.525; Time: 4.431\n",
            "Epoch: 68; Loss: 4.498; Time: 3.846\n",
            "Epoch: 69; Loss: 4.469; Time: 4.006\n",
            "Epoch: 70; Loss: 4.447; Time: 4.720\n",
            "Epoch: 71; Loss: 4.422; Time: 3.832\n",
            "Epoch: 72; Loss: 4.383; Time: 3.889\n",
            "Epoch: 73; Loss: 4.357; Time: 4.890\n",
            "Epoch: 74; Loss: 4.327; Time: 3.862\n",
            "Epoch: 75; Loss: 4.297; Time: 3.848\n",
            "Epoch: 76; Loss: 4.268; Time: 5.617\n",
            "Epoch: 77; Loss: 4.235; Time: 3.897\n",
            "Epoch: 78; Loss: 4.205; Time: 3.827\n",
            "Epoch: 79; Loss: 4.180; Time: 4.762\n",
            "Acc.: 0.7030; Time: 3.434\n",
            "Epoch: 80; Loss: 4.158; Time: 3.882\n",
            "Epoch: 81; Loss: 4.126; Time: 4.147\n",
            "Epoch: 82; Loss: 4.086; Time: 4.637\n",
            "Epoch: 83; Loss: 4.063; Time: 3.855\n",
            "Epoch: 84; Loss: 4.029; Time: 3.858\n",
            "Epoch: 85; Loss: 3.996; Time: 4.999\n",
            "Epoch: 86; Loss: 3.967; Time: 4.711\n",
            "Epoch: 87; Loss: 3.940; Time: 4.336\n",
            "Epoch: 88; Loss: 3.908; Time: 4.748\n",
            "Epoch: 89; Loss: 3.890; Time: 4.431\n",
            "Epoch: 90; Loss: 3.876; Time: 4.022\n",
            "Epoch: 91; Loss: 3.852; Time: 4.761\n",
            "Epoch: 92; Loss: 3.846; Time: 3.843\n",
            "Epoch: 93; Loss: 3.828; Time: 3.906\n",
            "Epoch: 94; Loss: 3.813; Time: 4.852\n",
            "Epoch: 95; Loss: 3.778; Time: 3.842\n",
            "Epoch: 96; Loss: 3.735; Time: 3.855\n",
            "Epoch: 97; Loss: 3.716; Time: 4.850\n",
            "Epoch: 98; Loss: 3.673; Time: 3.820\n",
            "Epoch: 99; Loss: 3.633; Time: 3.892\n",
            "Acc.: 0.7460; Time: 3.781\n"
          ]
        }
      ]
    }
  ]
}